{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Conv3D, Flatten, MaxPool2D, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.python.keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities.rectified_adam import RAdam\n",
    "import numpy as np\n",
    "import sys\n",
    "from utilities.pythonDB import writeToDB, deleteExistingPrimaryKeyDB\n",
    "from utilities.resnet import ResNet18, ResNet34\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples: X=30000, Y=30000\n"
     ]
    }
   ],
   "source": [
    "def get_random_data(data1, data2, low, high, max_samples=100):\n",
    "    _, H1, W1, C1 = data1.shape\n",
    "    _, N = data2.shape\n",
    "    suff_data1 = np.zeros((max_samples, H1, W1, C1))\n",
    "    suff_data2 = np.zeros((max_samples, N))\n",
    "    shuffles = np.random.randint(low, high+1, max_samples)\n",
    "    for idx in range(shuffles.shape[0]):\n",
    "        suff_data1[idx] = data1[idx, :, :, :]\n",
    "        suff_data2[idx] = data2[idx, :]\n",
    "    return suff_data1, suff_data2\n",
    "\n",
    "MAX_TRAINING = 30000\n",
    "\n",
    "#Loading CIFAR-10 dataset\n",
    "cifar = tf.keras.datasets.cifar10 \n",
    "(x_train, y_train), (_, _) = cifar.load_data()\n",
    "\n",
    "x_train_max, y_train = get_random_data(x_train, y_train, 0, x_train.shape[0], MAX_TRAINING)\n",
    "x_train = x_train_max / 255.0\n",
    "print (\"Number of Training Samples: X={}, Y={}\".format(x_train.shape[0], y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_preprocessors import flip_vertical_np, flip_horizontal_np, rotate_np, flip_rotate, \\\n",
    "perform_swirl_transformation, perform_random_affine_transform, mixed_transformations\n",
    "\n",
    "class TransformDataset(object):\n",
    "    def scale(self, X, x_min=0, x_max=1):\n",
    "        nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "        denom = X.max(axis=0) - X.min(axis=0)\n",
    "        denom[denom==0] = 1\n",
    "        return x_min + nom/denom \n",
    "    def return_function(self, name, im):\n",
    "        return getattr(self, 'if_' + name)(im)\n",
    "    def if_flip_vertical_np(self, im):\n",
    "        return self.scale(flip_vertical_np(im))\n",
    "    def if_flip_horizontal_np(self, im):\n",
    "        return self.scale(flip_horizontal_np(im))\n",
    "    def if_rotate_np(self, im):\n",
    "        return self.scale(rotate_np(im))\n",
    "    def if_flip_rotate(self, im):\n",
    "        return self.scale(flip_rotate(im))\n",
    "    def if_perform_swirl_transformation(self, im):\n",
    "        return self.scale(perform_swirl_transformation(im))\n",
    "    def if_perform_random_affine_transform(self, im):\n",
    "        return self.scale(perform_random_affine_transform(im))\n",
    "    def if_mixed_transformations(self, im):\n",
    "        return self.scale(mixed_transformations(im))\n",
    "\n",
    "def get_random_shuffle_set(data1, data2, ratios=None):\n",
    "    if ratios is None:\n",
    "        ratios = {\"flip_vertical_np\":.1, 'flip_horizontal_np':.1, 'rotate_np':.15, 'flip_rotate':.2, \\\n",
    "                  'perform_swirl_transformation':.1, 'perform_random_affine_transform':.15, 'mixed_transformations':.2}\n",
    "    _, H1, W1, C1 = data1.shape\n",
    "    N, _ = data2.shape\n",
    "    shuffles = np.random.randint(0, N, N)\n",
    "    low = 0\n",
    "    x_train_ret, y_train_ret, img_idx  = np.zeros((N, H1, W1, C1)), np.zeros((N,)), 0\n",
    "\n",
    "    for key in ratios.keys():\n",
    "        high = int(ratios.get(key) * N)\n",
    "        data = shuffles[low:low+high]\n",
    "        low += high\n",
    "        for idxs in data:\n",
    "            x_train_ret[img_idx] = TransformDataset().return_function(key, data1[idxs])\n",
    "            y_train_ret[img_idx] = data2[idxs]\n",
    "            img_idx += 1\n",
    "    return x_train_ret, y_train_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ret, y_train_ret = get_random_shuffle_set(x_train, y_train)\n",
    "np.save('../saved_numpy_data/cifar10_augmented_x_train.npy', x_train_ret)\n",
    "np.save('../saved_numpy_data/cifar10_augmented_y_train.npy', y_train_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_ret2 = np.load('../saved_numpy_data/cifar10_augmented_x_train.npy') \n",
    "# y_train_ret2 = np.load('../saved_numpy_data/cifar10_augmented_y_train.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 32, 32, 3) (30000,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train_ret.shape, y_train_ret.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs682)",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
